{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtensionLive.png  front  kernel.ipynb\tLICENSE  mle  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [],
   "source": [
    "\n",
    "nyt = 'mle/nyt.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing, string\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [],
   "source": [
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# def tokenize(text):\n",
    "#     tokens = []; word = \"\"\n",
    "#     for char in text.lower():\n",
    "#         if (char in string.whitespace) or (char in string.punctuation):\n",
    "#             if word:\n",
    "#                 tokens.append(word.strip(' '))\n",
    "#                 word = \"\"\n",
    "#         if char in string.punctuation:\n",
    "#             tokens.append(char)\n",
    "#         else:\n",
    "#             word += char\n",
    "#     return [word for word in tokens]\n",
    "\n",
    "# turn a doc into clean tokens\n",
    "def clean_doc(doc):\n",
    "    # replace '--' with a space ' '\n",
    "    doc = doc.replace('--', '')\n",
    "    # split into tokens by white space\n",
    "    tokens = doc.split()\n",
    "    #tokens = tokenize(doc)\n",
    "    # remove punctuation from each token\n",
    "    #table = str.maketrans('', '', string.punctuation)\n",
    "    #tokens = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    #tokens = [word for word in tokens if word.isalpha()]\n",
    "    # make lower case\n",
    "    #tokens = [word.lower() for word in tokens]\n",
    "    return tokens\n",
    "\n",
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheryl Sandberg was seething.\n",
      "\n",
      "Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, m\n",
      "['Sheryl', 'Sandberg', 'was', 'seething.', 'Inside', 'Facebook’s', 'Menlo', 'Park,', 'Calif.,', 'headquarters,', 'top', 'executives', 'gathered', 'in', 'the', 'glass-walled', 'conference', 'room', 'of', 'its', 'founder,', 'Mark', 'Zuckerberg.', 'It', 'was', 'September', '2017,', 'more', 'than', 'a', 'year', 'after', 'Facebook', 'engineers', 'discovered', 'suspicious', 'Russia-linked', 'activity', 'on', 'its', 'site,', 'an', 'early', 'warning', 'of', 'the', 'Kremlin', 'campaign', 'to', 'disrupt']\n",
      "Total Tokens: 5269\n",
      "Unique Tokens: 2016\n"
     ]
    }
   ],
   "source": [
    "# load document\n",
    "#in_filename = republic\n",
    "in_filename = nyt\n",
    "doc = load_doc(in_filename)\n",
    "print(doc[:200])\n",
    "\n",
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:50])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 5219\n"
     ]
    }
   ],
   "source": [
    "# organize into sequences of tokens\n",
    "length = 50\n",
    "sequences = list()\n",
    "for i in range(length, len(tokens)):\n",
    "    # select sequence of tokens\n",
    "    seq = tokens[i-length:i]\n",
    "    # convert into a line\n",
    "    line = ' '.join(seq)\n",
    "    # store\n",
    "    sequences.append(line)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "#out_filename = 'republic_sequences.txt'\n",
    "out_filename = 'mle/sequences.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [],
   "source": [
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "55969077747ed79521f91655c77b8560a42cd59a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheryl Sandberg was seething. Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt\r\n",
      "Sandberg was seething. Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt the\r\n"
     ]
    }
   ],
   "source": [
    "!head sequences.txt -n 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Word rNN (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jared/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Lambda\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sheryl Sandberg was seething. Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt',\n",
       " 'Sandberg was seething. Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt the',\n",
       " 'was seething. Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt the 2016',\n",
       " 'seething. Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt the 2016 American',\n",
       " 'Inside Facebook’s Menlo Park, Calif., headquarters, top executives gathered in the glass-walled conference room of its founder, Mark Zuckerberg. It was September 2017, more than a year after Facebook engineers discovered suspicious Russia-linked activity on its site, an early warning of the Kremlin campaign to disrupt the 2016 American election.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "in_filename = 'sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "lines[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1936"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(lines)\n",
    "# vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5219, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separate into input and output\n",
    "sequences = array(sequences)\n",
    "sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "f2b1f41a6423cc1ba2a71494dcbbad7bef1148a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "764b2530b70191232c943a089164cc2d77171dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 50)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences[0]), len(sequences[1]),len(sequences[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5219, 49)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = X.shape[1]\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 49, 50)            96800     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 49, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1936)              195536    \n",
      "=================================================================\n",
      "Total params: 443,236\n",
      "Trainable params: 443,236\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 7.1264 - acc: 0.0374\n",
      "Epoch 2/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 6.5557 - acc: 0.0519\n",
      "Epoch 3/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 6.4769 - acc: 0.0519\n",
      "Epoch 4/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 6.4597 - acc: 0.0519\n",
      "Epoch 5/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 6.4460 - acc: 0.0519\n",
      "Epoch 6/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 6.4091 - acc: 0.0519\n",
      "Epoch 7/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 6.2771 - acc: 0.0519\n",
      "Epoch 8/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 6.1233 - acc: 0.0535\n",
      "Epoch 9/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 5.9828 - acc: 0.0548\n",
      "Epoch 10/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 5.8753 - acc: 0.0561\n",
      "Epoch 11/200\n",
      "5219/5219 [==============================] - 21s 4ms/step - loss: 5.7953 - acc: 0.0548\n",
      "Epoch 12/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 5.7283 - acc: 0.0575\n",
      "Epoch 13/200\n",
      "5219/5219 [==============================] - 21s 4ms/step - loss: 5.6732 - acc: 0.0592\n",
      "Epoch 14/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 5.6076 - acc: 0.0617\n",
      "Epoch 15/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 5.5270 - acc: 0.0602\n",
      "Epoch 16/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 5.4552 - acc: 0.0586\n",
      "Epoch 17/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 5.3904 - acc: 0.0628\n",
      "Epoch 18/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 5.3349 - acc: 0.0669\n",
      "Epoch 19/200\n",
      "5219/5219 [==============================] - 21s 4ms/step - loss: 5.2790 - acc: 0.0659\n",
      "Epoch 20/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 5.2292 - acc: 0.0665\n",
      "Epoch 21/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 5.1775 - acc: 0.0705\n",
      "Epoch 22/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 5.1284 - acc: 0.0743\n",
      "Epoch 23/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 5.0782 - acc: 0.0751\n",
      "Epoch 24/200\n",
      "5219/5219 [==============================] - 21s 4ms/step - loss: 5.0281 - acc: 0.0816\n",
      "Epoch 25/200\n",
      "5219/5219 [==============================] - 21s 4ms/step - loss: 4.9763 - acc: 0.0822\n",
      "Epoch 26/200\n",
      "5219/5219 [==============================] - 19s 4ms/step - loss: 4.9245 - acc: 0.0839\n",
      "Epoch 27/200\n",
      "5219/5219 [==============================] - 20s 4ms/step - loss: 4.8760 - acc: 0.0839\n",
      "Epoch 28/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.8315 - acc: 0.0889\n",
      "Epoch 29/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 4.7964 - acc: 0.0895\n",
      "Epoch 30/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 4.7490 - acc: 0.0937\n",
      "Epoch 31/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.7083 - acc: 0.0906\n",
      "Epoch 32/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 4.6650 - acc: 0.0981\n",
      "Epoch 33/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 4.6210 - acc: 0.1006\n",
      "Epoch 34/200\n",
      "5219/5219 [==============================] - 21s 4ms/step - loss: 4.5827 - acc: 0.0981\n",
      "Epoch 35/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.5423 - acc: 0.1004\n",
      "Epoch 36/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 4.5017 - acc: 0.1006\n",
      "Epoch 37/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.4597 - acc: 0.1071\n",
      "Epoch 38/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 4.4199 - acc: 0.1065\n",
      "Epoch 39/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 4.3790 - acc: 0.1129\n",
      "Epoch 40/200\n",
      "5219/5219 [==============================] - 23s 5ms/step - loss: 4.3377 - acc: 0.1127\n",
      "Epoch 41/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.2967 - acc: 0.1100\n",
      "Epoch 42/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 4.2527 - acc: 0.1169\n",
      "Epoch 43/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.2147 - acc: 0.1207\n",
      "Epoch 44/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 4.1774 - acc: 0.1192\n",
      "Epoch 45/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 4.1352 - acc: 0.1236\n",
      "Epoch 46/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 4.0992 - acc: 0.1267\n",
      "Epoch 47/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 4.0534 - acc: 0.1265\n",
      "Epoch 48/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 4.0141 - acc: 0.1305\n",
      "Epoch 49/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.9844 - acc: 0.1311\n",
      "Epoch 50/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 3.9494 - acc: 0.1334\n",
      "Epoch 51/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 3.9110 - acc: 0.1416\n",
      "Epoch 52/200\n",
      "5219/5219 [==============================] - 26s 5ms/step - loss: 3.8720 - acc: 0.1387\n",
      "Epoch 53/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 3.8444 - acc: 0.1399\n",
      "Epoch 54/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 3.8380 - acc: 0.1464\n",
      "Epoch 55/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 3.7906 - acc: 0.1404\n",
      "Epoch 56/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.7378 - acc: 0.1487\n",
      "Epoch 57/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.7085 - acc: 0.1521\n",
      "Epoch 58/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.6686 - acc: 0.1579\n",
      "Epoch 59/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.6358 - acc: 0.1565\n",
      "Epoch 60/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.5995 - acc: 0.1596\n",
      "Epoch 61/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.5643 - acc: 0.1686\n",
      "Epoch 62/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.5439 - acc: 0.1669\n",
      "Epoch 63/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.4943 - acc: 0.1701\n",
      "Epoch 64/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.4633 - acc: 0.1805\n",
      "Epoch 65/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.4234 - acc: 0.1782\n",
      "Epoch 66/200\n",
      "5219/5219 [==============================] - 22s 4ms/step - loss: 3.3877 - acc: 0.1803\n",
      "Epoch 67/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 3.3643 - acc: 0.1845\n",
      "Epoch 68/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 3.3248 - acc: 0.1908\n",
      "Epoch 69/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 3.2862 - acc: 0.1937\n",
      "Epoch 70/200\n",
      "5219/5219 [==============================] - 23s 4ms/step - loss: 3.2501 - acc: 0.2004\n",
      "Epoch 71/200\n",
      "5219/5219 [==============================] - 24s 5ms/step - loss: 3.2184 - acc: 0.2014\n",
      "Epoch 72/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 3.1826 - acc: 0.2077\n",
      "Epoch 73/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5219/5219 [==============================] - 27s 5ms/step - loss: 3.1547 - acc: 0.2179\n",
      "Epoch 74/200\n",
      "5219/5219 [==============================] - 26s 5ms/step - loss: 3.1206 - acc: 0.2180\n",
      "Epoch 75/200\n",
      "5219/5219 [==============================] - 25s 5ms/step - loss: 3.0751 - acc: 0.2315\n",
      "Epoch 76/200\n",
      "2560/5219 [=============>................] - ETA: 13s - loss: 2.9319 - acc: 0.2621"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, batch_size=128, epochs=200)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "model.save('model.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)\n",
    "\n",
    "# load cleaned text sequences\n",
    "in_filename = 'mle/sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    "\n",
    "# load the model\n",
    "model = load_model('model.h5')\n",
    "\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer.pkl', 'rb'))\n",
    "\n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the company was ntk network — had been campaigns, of scrambled “our data — had been campaigns, of scrambled “our data — had been campaigns, of scrambled “our data — had been campaigns, of scrambled “our data — had been campaigns, of scrambled “our data — had been campaigns, of\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b51a4d21630717e92b9f7a23eb53fc6c929bd159"
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b51a4d21630717e92b9f7a23eb53fc6c929bd159"
   },
   "outputs": [],
   "source": [
    "plot_model(model,'model.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
